{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e06c56c-1f6f-44de-991d-ff4cbcbdd251",
   "metadata": {},
   "source": [
    "## CSVs to .h5 conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74293bcb-84cf-4e8a-9a99-5941872d5e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import gc\n",
    "from ftse.data.Dataset import UnwindowedDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af1b592-9335-4e37-beee-df2af1a15d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIRS = [\n",
    "    '/workspace/research/ftse/ftse/notebooks/'\n",
    "]\n",
    "\n",
    "H5_FILE = '/workspace/research/ftse/ftse/notebooks/testing3.h5'\n",
    "\n",
    "root_dirs=ROOT_DIRS\n",
    "h5_file=H5_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40daeecd-355b-43df-aa2f-ec4fdeed1e27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root_prefix notebooks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c8573278754c42845a940a0f765dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets in /workspace/research/ftse/ftse/notebooks/:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e475e0bfeb49d9add6fab66c36bdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Michigan:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f445ea00e3d4415ba33115d55ce8e556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NCSV: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f48ac7207d49b6815761c4351c7406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Gyrometer:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5101bb92e54a3ea8dc355b6edaf2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "OCSV:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef69a3a1834f8085765c44275748f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Illinois:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/indices.ipynb\n",
      "skipping /workspace/research/ftse/ftse/notebooks/Satya_data.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69da935147745aa84f9aaa4cdbeeb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Maryland:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f703141cb0449eb06f749a7677db42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "California:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/testing3.h5\n",
      "skipping /workspace/research/ftse/ftse/notebooks/temp2.h5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7f4ac9d81648e8b12719a32b171ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".ipynb_checkpoints:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2619578cc8c040c9ac8d92b52f62b417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Wyoming:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccc2c49363f4633afaa15bab2db509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Delaware:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/Modeling.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bb59171d4f4397b23a75f15f4c886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IOCSV:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/temp.h5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba1389692da4ddba9cbabf9b98a97bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Florida:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/Untitled.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2be1eb1e7cd450082751121d5ee1e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Airquality_pattern:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf43ed862c7f4ca38f72e6b64cddf822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "turbofan:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83444f046dfe4c0f80b75bcf871a5781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f36e56bff834a5d8b37a143b30b21de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accelerometer:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de2d625ddfc420e95d72e99c5312f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ICSV: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1faecae4e34e359477717e215d6deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Texas:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/jepa.ipynb\n",
      "skipping /workspace/research/ftse/ftse/notebooks/evals-classif.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0134981c2e4711a3359b6964b7615f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NewYork:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/evals.ipynb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a39b1d6a11410fa84b5b586bb35ba0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IBCSV:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping /workspace/research/ftse/ftse/notebooks/log.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38936870eb5d4defb62f1b5ceb89c23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BCSV:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397000237e1a420e91b9bb01f936daa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".git:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File(h5_file, \"w\") as h5f:\n",
    "    for root_dir in root_dirs:\n",
    "        root_prefix = os.path.basename(os.path.normpath(root_dir))\n",
    "        print(\"root_prefix\", root_prefix)\n",
    "        for dataset_folder in tqdm(os.listdir(root_dir), desc=f\"Datasets in {root_dir}\"):\n",
    "            #print(\"dataset_folder\", dataset_folder)\n",
    "            dataset_path = os.path.join(root_dir, dataset_folder)\n",
    "            if not os.path.isdir(dataset_path):\n",
    "                print(\"skipping\", dataset_path)\n",
    "                continue  # Skip non-directory items\n",
    "            label_counts = {}\n",
    "\n",
    "            for csv_file in tqdm(os.listdir(dataset_path), desc=dataset_folder, leave=False):\n",
    "                if not csv_file.lower().endswith(\".csv\"):\n",
    "                    continue\n",
    "\n",
    "                # Example filename: \"file_5_Normal Operation.csv\"\n",
    "                # Extract label: take everything after the second underscore and strip \".csv\".\n",
    "                parts = csv_file.split('_')\n",
    "                if len(parts) >= 3:\n",
    "                    label = '_'.join(parts[2:]).replace('.csv', '')\n",
    "                else:\n",
    "                    label = \"Unknown\"\n",
    "\n",
    "                # Initialize or update the file index counter for this label.\n",
    "                if label not in label_counts:\n",
    "                    label_counts[label] = 0\n",
    "                file_idx = label_counts[label]\n",
    "                label_counts[label] += 1\n",
    "\n",
    "                # Read the CSV file.\n",
    "                csv_path = os.path.join(dataset_path, csv_file)\n",
    "                df = pd.read_csv(csv_path)\n",
    "                # Drop unwanted columns.\n",
    "                cols_to_drop = ['Unnamed: 0', 'time_sec', 'Time', 'Label']\n",
    "                df = df.drop([col for col in cols_to_drop if col in df.columns], axis=1)\n",
    "                # Save the column names as metadata.\n",
    "                column_names = df.columns.tolist()\n",
    "                data_array = df.to_numpy()\n",
    "                # Create a flat key in the format:\n",
    "                # \"root_prefix___dataset_folder___label___file_idx\"\n",
    "                key = f\"{dataset_folder}___{label}___{file_idx}\"\n",
    "                #print(key)\n",
    "                dset = h5f.create_dataset(key, data=data_array)\n",
    "                dset.attrs[\"descriptions\"] = list(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c26c1a-dbc3-4b17-b86a-b9f9b0042732",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file=H5_FILE\n",
    "window_size=None\n",
    "stride=1\n",
    "concat=True\n",
    "datasets = defaultdict(list)\n",
    "f = h5py.File(h5_file, 'r')\n",
    "for key in f.keys():\n",
    "    dataset_name, label, file_idx = key.split('___')\n",
    "    datasets[dataset_name].append(\n",
    "        UnwindowedDataset(\n",
    "            data=f[key],\n",
    "            dataset_name=dataset_name,\n",
    "            descriptions=f[key].attrs[\"descriptions\"],\n",
    "            label=label\n",
    "        )\n",
    "    )\n",
    "\n",
    "if window_size and stride:\n",
    "    for dataset_name in datasets:\n",
    "        datasets[dataset_name] = [\n",
    "            dataset.window(window_size=window_size, stride=stride)\n",
    "            for dataset in datasets[dataset_name]\n",
    "        ]\n",
    "\n",
    "if concat:\n",
    "    for dataset_name in datasets:\n",
    "        datasets[dataset_name] = torch.utils.data.ConcatDataset(\n",
    "            datasets[dataset_name]\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3700d5ab-398f-49cf-bab6-71ddbad403d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Accelerometer', 'Airquality_pattern', 'BCSV', 'California', 'Delaware', 'Florida', 'Gyrometer', 'IBCSV', 'IOCSV', 'Illinois', 'Maryland', 'Michigan', 'NewYork', 'OCSV', 'Texas', 'Wyoming', 'turbofan']\n"
     ]
    }
   ],
   "source": [
    "print(list(datasets.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afbd6f50-3ea8-4a10-b42b-a51b8b2f17c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ftse.data.Dataset.UnwindowedDataset at 0x7ce9836dd810>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836c7910>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836af0d0>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b8f50>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b9210>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b8d90>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b9110>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b8490>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b9d10>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836b9f10>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836ba150>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836ba390>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836ba5d0>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836ba810>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce9836baa50>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce984a58e90>,\n",
       " <ftse.data.Dataset.UnwindowedDataset at 0x7ce98439d950>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['Gyrometer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2b16e-c413-40cb-8f57-ceaaf929c3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a5e4a5b-37c6-459e-ac42-ab91eaf4c358",
   "metadata": {},
   "source": [
    "### HUST bearing: a practical dataset for ball bearing fault diagnosis\n",
    "https://data.mendeley.com/datasets/cbv7jyx4p9/3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4edf816f-55ae-416c-9d19-a048345e736d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca3e18de-fff1-4112-8354-285c21f9a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_mapping = {\n",
    "    'BMat': 'BCSV',\n",
    "    'IBMat': 'IBCSV',\n",
    "    'IOMat': 'IOCSV',\n",
    "    'OBMat': 'OCSV',\n",
    "    'NMat': 'NCSV',\n",
    "    'IMat': 'ICSV',\n",
    "    'OMat': 'OCSV'\n",
    "}\n",
    "defect_map = {\n",
    "    \"I\": \"Inner\",\n",
    "    \"O\": \"Outer\",\n",
    "    \"B\": \"Ball\",\n",
    "    \"IO\": \"Inner_and_Outer\",\n",
    "    \"IB\": \"Inner_and_Ball\",\n",
    "    \"OB\": \"Outer_and_Ball\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23eb8f76-fc2e-49d1-aa96-eac2ee88b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({('ru', 'rpm'): 8, ('ru_raw',): 4})\n",
      "defaultdict(<class 'list'>, {('ru', 'rpm'): ['B604.mat', 'B800.mat', 'B600.mat', 'B804.mat', 'B700.mat', 'B602.mat', 'B500.mat', 'B802.mat'], ('ru_raw',): ['B502.mat', 'B704.mat', 'B702.mat', 'B504.mat']})\n",
      "('ru', 'rpm')\n",
      "Counter({('ru', 'rpm'): 4, ('ru_raw',): 3})\n",
      "defaultdict(<class 'list'>, {('ru_raw',): ['IB500.mat', 'IB504.mat', 'IB502.mat'], ('ru', 'rpm'): ['IB600.mat', 'IB604.mat', 'IB700.mat', 'IB602.mat']})\n",
      "('ru', 'rpm')\n",
      "Counter({('ru', 'rpm'): 5, ('ru_raw',): 3})\n",
      "defaultdict(<class 'list'>, {('ru', 'rpm'): ['IO404.mat', 'IO402.mat', 'IO602.mat', 'IO600.mat', 'IO400.mat'], ('ru_raw',): ['IO504.mat', 'IO502.mat', 'IO500.mat']})\n",
      "('ru', 'rpm')\n",
      "Counter({('ru', 'rpm'): 9})\n",
      "defaultdict(<class 'list'>, {('ru', 'rpm'): ['OB404.mat', 'OB402.mat', 'OB600.mat', 'OB604.mat', 'OB602.mat', 'OB502.mat', 'OB504.mat', 'OB700.mat', 'OB500.mat']})\n",
      "('ru', 'rpm')\n",
      "Skipping NMat: directory 'test/NMat' does not exist.\n",
      "Skipping IMat: directory 'test/IMat' does not exist.\n",
      "Skipping OMat: directory 'test/OMat' does not exist.\n"
     ]
    }
   ],
   "source": [
    "for source_dir, destination_dir in folder_mapping.items():\n",
    "    os.makedirs(destination_dir, exist_ok=True)\n",
    "    source_folder_name = os.path.basename(source_dir)\n",
    "    folder_path = os.path.join(\"test\", source_dir)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"Skipping {source_dir}: directory 'test/{source_dir}' does not exist.\")\n",
    "        continue\n",
    "    schema_counter = Counter()\n",
    "    file_schema_map = defaultdict(list)\n",
    "    \n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith(\".mat\"):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            mat_data = loadmat(file_path)\n",
    "            if 'data' in mat_data:\n",
    "                if ('ru' in mat_data and 'rpm' in mat_data):\n",
    "                    schema = ('ru', 'rpm')\n",
    "                elif 'ru_raw' in mat_data:\n",
    "                    schema = ('ru_raw',)\n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "                schema_counter[schema] += 1\n",
    "                file_schema_map[schema].append(file)\n",
    "    print(schema_counter)\n",
    "    print(file_schema_map)\n",
    "    dominant_schema = schema_counter.most_common(1)[0][0]\n",
    "    print(dominant_schema)\n",
    "    tracker = 0\n",
    "    for file in file_schema_map[dominant_schema]:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        key_label_key=\"None\"\n",
    "        key_label_value=\"None\"\n",
    "        for key in sorted(defect_map.keys(), key=len, reverse=True):\n",
    "            if file.startswith(key):\n",
    "                key_label_key=key\n",
    "                key_label_value=defect_map[key_label_key]\n",
    "                break\n",
    "        if key_label_key == \"None\":\n",
    "            continue \n",
    "        mat_data = loadmat(file_path)\n",
    "        fs = float(mat_data['fs'])\n",
    "        if 'data' in mat_data:\n",
    "            vibration = mat_data['data'].flatten()\n",
    "            time = np.arange(len(vibration)) / fs\n",
    "            if dominant_schema == ('ru', 'rpm'):\n",
    "                ru = mat_data['ru'].flatten()\n",
    "                rpm = mat_data['rpm'].flatten()\n",
    "                min_len = min(len(vibration), len(ru), len(rpm))\n",
    "                df = pd.DataFrame({\n",
    "                    'time_sec': time[:min_len],\n",
    "                    'Vibration signal': vibration[:min_len],\n",
    "                    'ru: Vibration signal during run-up time': ru[:min_len],\n",
    "                    'rpm: Shaft Angular velocity in RPM during run-up time': rpm[:min_len]\n",
    "                })\n",
    "            elif dominant_schema == ('ru_raw',):\n",
    "                ru = mat_data['ru_raw'].flatten()\n",
    "                min_len = min(len(vibration), len(ru))\n",
    "                df = pd.DataFrame({\n",
    "                    'time_sec': time[:min_len],\n",
    "                    'Vibration signal': vibration[:min_len],\n",
    "                    'ru_raw: Vibration signal during run-up time': ru[:min_len]\n",
    "                })\n",
    "            output_filename = f\"file_{tracker}_{key_label_value}.csv\"\n",
    "            output_path = os.path.join(destination_dir,output_filename)\n",
    "            df.to_csv(output_path, index = False)\n",
    "            tracker+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1106f0-7130-4a01-9a27-6bc195dfb0ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b8c9f64-1127-4ff6-9c81-9fda62c1f212",
   "metadata": {},
   "source": [
    "### Air Data: Air Quality Data Collected at Outdoor Monitors Across the US\n",
    "https://www.epa.gov/outdoor-air-quality-data/download-daily-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "282a7bbd-a791-4479-8710-13ba094dd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11f495c8-920a-464e-8c09-f96e6244d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'Il'\n",
    "folder_path = os.path.join(\"test\", source_dir)\n",
    "output_dir = 'Illinois'\n",
    "os.makedirs(output_dir, exist_ok= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1df3cd65-8487-488a-9f3c-1bc48b6f1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(folder_path): \n",
    "    df = pd.read_csv(os.path.join(folder_path, file))\n",
    "    df = df.drop(columns=[col for col in df.columns if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col])])\n",
    "    df.rename(columns={'Daily Obs Count': 'Daily Observations Count'}, inplace=True)\n",
    "    df.drop(columns=['POC', 'AQS Parameter Code', 'Method Code', 'CBSA Code', 'State FIPS Code', 'County FIPS Code', 'Site Latitude', 'Site Longitude'], inplace=True)\n",
    "    grouped = df.groupby('Site ID')\n",
    "    for index, (site_id, group) in enumerate(grouped):\n",
    "        filename = f'file_{index}_NO.csv'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        group.drop(columns=['Site ID'], inplace=True)\n",
    "        group.to_csv(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7c67b-df52-4f98-900e-557408fbc68c",
   "metadata": {},
   "source": [
    "### Air quality pattern data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "625eae2b-c898-40c9-99b7-3d2fedaa7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97387cb6-8791-44d2-a92d-5198e9b2d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(os.path.join(\"test\",\"airquality_pattern.csv\"))\n",
    "df = df.iloc[2:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6259b464-b13e-4ebb-baf4-bdb153d3d96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        try:\n",
    "            df[col] = pd.to_numeric(df[col], errors='raise')\n",
    "        except ValueError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4754af-c538-400e-9062-ba50e1de2272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                             object\n",
       "Time GMT -4                      object\n",
       "Timestamp                         int64\n",
       "Ozone - Low Conc.               float64\n",
       "Hydrogen Sulfide - Low Conc.    float64\n",
       "Total VOCs (ppm) - PID          float64\n",
       "Carbon Dioxide - Low Conc.      float64\n",
       "Particulate Matter 1            float64\n",
       "Particulate Matter 2.5          float64\n",
       "Particulate Matter 10           float64\n",
       "Temperature (Internal)          float64\n",
       "Humidity (Internal)             float64\n",
       "Temperature (External)          float64\n",
       "Humidity (External)             float64\n",
       "Latitude                        float64\n",
       "Longitude                       float64\n",
       "Unnamed: 16                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bf5433e-a4ee-4e61-9cc4-23b74e729c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"Timestamp\", \"Latitude\", \"Longitude\", \"Unnamed: 16\"] + [\n",
    "    col for col in df.columns if df[col].dtype == 'object' or pd.api.types.is_string_dtype(df[col])\n",
    "]\n",
    "df = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da710e55-5af2-44a8-a989-8aa7ca1b61a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ozone - Low Conc.               float64\n",
       "Hydrogen Sulfide - Low Conc.    float64\n",
       "Total VOCs (ppm) - PID          float64\n",
       "Carbon Dioxide - Low Conc.      float64\n",
       "Particulate Matter 1            float64\n",
       "Particulate Matter 2.5          float64\n",
       "Particulate Matter 10           float64\n",
       "Temperature (Internal)          float64\n",
       "Humidity (Internal)             float64\n",
       "Temperature (External)          float64\n",
       "Humidity (External)             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4260084f-5440-4d6e-801e-20e9f12dd2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ozone - Low Conc.</th>\n",
       "      <th>Hydrogen Sulfide - Low Conc.</th>\n",
       "      <th>Total VOCs (ppm) - PID</th>\n",
       "      <th>Carbon Dioxide - Low Conc.</th>\n",
       "      <th>Particulate Matter 1</th>\n",
       "      <th>Particulate Matter 2.5</th>\n",
       "      <th>Particulate Matter 10</th>\n",
       "      <th>Temperature (Internal)</th>\n",
       "      <th>Humidity (Internal)</th>\n",
       "      <th>Temperature (External)</th>\n",
       "      <th>Humidity (External)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.402</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>382.043</td>\n",
       "      <td>2.719</td>\n",
       "      <td>3.164</td>\n",
       "      <td>3.506</td>\n",
       "      <td>25.82</td>\n",
       "      <td>44.41</td>\n",
       "      <td>17.68</td>\n",
       "      <td>68.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.446</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192</td>\n",
       "      <td>379.549</td>\n",
       "      <td>2.652</td>\n",
       "      <td>2.846</td>\n",
       "      <td>2.886</td>\n",
       "      <td>25.88</td>\n",
       "      <td>44.33</td>\n",
       "      <td>17.69</td>\n",
       "      <td>69.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188</td>\n",
       "      <td>377.549</td>\n",
       "      <td>2.029</td>\n",
       "      <td>2.172</td>\n",
       "      <td>2.197</td>\n",
       "      <td>25.78</td>\n",
       "      <td>44.29</td>\n",
       "      <td>17.75</td>\n",
       "      <td>68.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183</td>\n",
       "      <td>377.316</td>\n",
       "      <td>3.183</td>\n",
       "      <td>3.645</td>\n",
       "      <td>3.977</td>\n",
       "      <td>25.90</td>\n",
       "      <td>44.44</td>\n",
       "      <td>17.69</td>\n",
       "      <td>68.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184</td>\n",
       "      <td>381.616</td>\n",
       "      <td>2.995</td>\n",
       "      <td>3.440</td>\n",
       "      <td>3.766</td>\n",
       "      <td>25.91</td>\n",
       "      <td>44.19</td>\n",
       "      <td>17.70</td>\n",
       "      <td>67.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ozone - Low Conc.  Hydrogen Sulfide - Low Conc.  Total VOCs (ppm) - PID  \\\n",
       "0              0.402                           0.0                   0.191   \n",
       "1              0.446                           0.0                   0.192   \n",
       "2              0.412                           0.0                   0.188   \n",
       "3              0.417                           0.0                   0.183   \n",
       "4              0.433                           0.0                   0.184   \n",
       "\n",
       "   Carbon Dioxide - Low Conc.  Particulate Matter 1  Particulate Matter 2.5  \\\n",
       "0                     382.043                 2.719                   3.164   \n",
       "1                     379.549                 2.652                   2.846   \n",
       "2                     377.549                 2.029                   2.172   \n",
       "3                     377.316                 3.183                   3.645   \n",
       "4                     381.616                 2.995                   3.440   \n",
       "\n",
       "   Particulate Matter 10  Temperature (Internal)  Humidity (Internal)  \\\n",
       "0                  3.506                   25.82                44.41   \n",
       "1                  2.886                   25.88                44.33   \n",
       "2                  2.197                   25.78                44.29   \n",
       "3                  3.977                   25.90                44.44   \n",
       "4                  3.766                   25.91                44.19   \n",
       "\n",
       "   Temperature (External)  Humidity (External)  \n",
       "0                   17.68                68.42  \n",
       "1                   17.69                69.42  \n",
       "2                   17.75                68.52  \n",
       "3                   17.69                68.20  \n",
       "4                   17.70                67.68  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "047dfdbc-4d8f-4b7f-bb41-a8b0511a8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"file_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5cebe2-8c7f-4d77-a2d9-dbb51d74e49a",
   "metadata": {},
   "source": [
    "### NASA Turbofan Jet Engine Data Set\n",
    "https://www.kaggle.com/datasets/behrad3d/nasa-cmaps/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07794774-0dda-41a3-afe9-c901b53a4f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sm_1': '(Fan inlet temperature) (◦R)',\n",
       " 'sm_2': '(LPC outlet temperature) (◦R)',\n",
       " 'sm_3': '(HPC outlet temperature) (◦R)',\n",
       " 'sm_4': '(LPT outlet temperature) (◦R)',\n",
       " 'sm_5': '(Fan inlet Pressure) (psia)',\n",
       " 'sm_6': '(bypass-duct pressure) (psia)',\n",
       " 'sm_7': '(HPC outlet pressure) (psia)',\n",
       " 'sm_8': '(Physical fan speed) (rpm)',\n",
       " 'sm_9': '(Physical core speed) (rpm)',\n",
       " 'sm_10': '(Engine pressure ratio(P50/P2)',\n",
       " 'sm_11': '(HPC outlet Static pressure) (psia)',\n",
       " 'sm_12': '(Ratio of fuel flow to Ps30) (pps/psia)',\n",
       " 'sm_13': '(Corrected fan speed) (rpm)',\n",
       " 'sm_14': '(Corrected core speed) (rpm)',\n",
       " 'sm_15': '(Bypass Ratio) ',\n",
       " 'sm_16': '(Burner fuel-air ratio)',\n",
       " 'sm_17': '(Bleed Enthalpy)',\n",
       " 'sm_18': '(Required fan speed)',\n",
       " 'sm_19': '(Required fan conversion speed)',\n",
       " 'sm_20': '(High-pressure turbines Cool air flow)',\n",
       " 'sm_21': '(Low-pressure turbines Cool air flow)'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['engine', 'time', 'op_setting_1', 'op_setting_2', \n",
    "                'op_setting_3'] + [f'sm_{i}' for i in range(1, 22)]\n",
    "Sensor_dictionary={}\n",
    "dict_list=[ \"(Fan inlet temperature) (◦R)\",\n",
    "\"(LPC outlet temperature) (◦R)\",\n",
    "\"(HPC outlet temperature) (◦R)\",\n",
    "\"(LPT outlet temperature) (◦R)\",\n",
    "\"(Fan inlet Pressure) (psia)\",\n",
    "\"(bypass-duct pressure) (psia)\",\n",
    "\"(HPC outlet pressure) (psia)\",\n",
    "\"(Physical fan speed) (rpm)\",\n",
    "\"(Physical core speed) (rpm)\",\n",
    "\"(Engine pressure ratio(P50/P2)\",\n",
    "\"(HPC outlet Static pressure) (psia)\",\n",
    "\"(Ratio of fuel flow to Ps30) (pps/psia)\",\n",
    "\"(Corrected fan speed) (rpm)\",\n",
    "\"(Corrected core speed) (rpm)\",\n",
    "\"(Bypass Ratio) \",\n",
    "\"(Burner fuel-air ratio)\",\n",
    "\"(Bleed Enthalpy)\",\n",
    "\"(Required fan speed)\",\n",
    "\"(Required fan conversion speed)\",\n",
    "\"(High-pressure turbines Cool air flow)\",\n",
    "\"(Low-pressure turbines Cool air flow)\" ]\n",
    "\n",
    "i=1\n",
    "for x in dict_list :\n",
    "    Sensor_dictionary[f'sm_{i}']=x\n",
    "    i+=1\n",
    "Sensor_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8892b06-22e8-46d2-ada9-e8dc5998ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt_file in tqdm(os.listdir(\"test/turbofan\"), leave=False):\n",
    "    if not txt_file.endswith(\".txt\"):\n",
    "        continue\n",
    "    df = pd.read_csv(os.path.join(\"test/turbofan\",txt_file),sep = ' ',header=None,names=column_names , index_col=False )\n",
    "    df.rename(columns=Sensor_dictionary, inplace=True)\n",
    "    csv_filename = txt_file.replace(\".txt\", \".csv\")\n",
    "    df.drop(columns=[\"engine\", \"time\"], inplace= True)\n",
    "    df.to_csv(os.path.join(\"test/turbofan\",csv_filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab18413-839a-40a1-968b-75e7ca264e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36e6be29-7241-4e97-b946-b2550a0f3acb",
   "metadata": {},
   "source": [
    "### HASC (Human Activity Sensing Consortium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9368fe5-1426-498d-836c-45530477995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"test/hasc/seg1011.csv\")\n",
    "df.columns = ['timestamp', 'X-axis', 'Y-axis', 'Z-axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81bb2a-4252-4018-8a43-77c8198a2203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc855f46-3b6a-44f1-9f9f-79c09d29acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['timestamp'], errors='ignore')\n",
    "df.to_csv(\"Hasc/Gyrometer/file_15_BuildingStairMove.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b4344-179c-45d3-b249-e63aadda0908",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test/hasc/hasc-111018-165936.label\", \"r\") as f:\n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "print(labels[:5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242b8c5-a82f-4eb1-acd4-0646d9a84893",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa0eafc-9196-4cf3-9629-126210b4b2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc4ff5c4-b051-4fc6-a956-fed9b312c918",
   "metadata": {},
   "source": [
    "### Sleep-EDF Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b981ed-104e-46ca-ae1f-3b77e1b80803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bffdee-efe4-43d9-a4a8-0aebe6318131",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(\"test/sleepedf/SC4101E0-PSG.edf\", preload=True)\n",
    "print(raw.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465aff84-b7ba-47ff-9a57-59d7aebdbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, times = raw.get_data(return_times=True)\n",
    "df = pd.DataFrame(data.T, columns=raw.ch_names)\n",
    "df[\"timestamp\"] = times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319be99-80be-4b85-8618-adf8010034e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_mapping={\n",
    "    'EEG Fpz-Cz' : 'EEG channel 1 (frontal to central)',\n",
    "    'EEG Pz-Oz' : 'EEG channel 2 (parietal to occipital)',\n",
    "    'EOG horizontal' : 'Electrooculogram (eye movements)',\n",
    "    'EMG submental' : 'Electromyogram (muscle activity)'\n",
    "}\n",
    "df.drop(columns=[\"Event marker\", \"timestamp\"], inplace=True)\n",
    "df.rename(columns = columns_mapping, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7db88-4d78-4334-8a7c-8aad1d108e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sleepedf/file_14_Healthy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806dd991-5cbe-4b12-aee2-6371cee9ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"sleepedf\"\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        # Read the CSV\n",
    "        df = pd.read_csv(file_path, index_col=0)  # This assumes the first column is the index\n",
    "\n",
    "        # If the index is just 0, 1, 2... reset it\n",
    "        if df.index.is_monotonic_increasing and df.index.equals(pd.RangeIndex(start=0, stop=len(df))):\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        # Save back to same file without the index\n",
    "        df.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a5733-24e3-4269-a45c-f4def602bf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "297c0897-2fea-4a52-86ec-dc5052daaf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: body_acc_timeseries.csv → shape: (941056, 4)\n",
      "Saved: body_gyro_timeseries.csv → shape: (941056, 4)\n",
      "Saved: total_acc_timeseries.csv → shape: (941056, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base path\n",
    "base_path = \"test/HAR/Inertial Signals\"\n",
    "output_path = \"formatted_timeseries/train\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "sensors = {\n",
    "    \"body_acc\": \"body_acc\",\n",
    "    \"body_gyro\": \"body_gyro\",\n",
    "    \"total_acc\": \"total_acc\"\n",
    "}\n",
    "\n",
    "# Axis list\n",
    "axes = [\"x\", \"y\", \"z\"]\n",
    "\n",
    "for sensor_name, file_prefix in sensors.items():\n",
    "    # Load x, y, z axis files\n",
    "    data_axes = {}\n",
    "    for axis in axes:\n",
    "        file_name = f\"{file_prefix}_{axis}_train.txt\"\n",
    "        full_path = os.path.join(base_path, file_name)\n",
    "        data_axes[axis] = np.loadtxt(full_path)  # shape: (n_samples, 128)\n",
    "\n",
    "    # Now reformat into time-major format: one long time series per axis\n",
    "    n_samples, n_timesteps = data_axes[\"x\"].shape\n",
    "\n",
    "    # For each time step across all samples\n",
    "    rows = []\n",
    "    for t in range(n_timesteps):\n",
    "        # Stack all sample values at time t for each axis\n",
    "        for sample in range(n_samples):\n",
    "            row = {\n",
    "                \"timestep\": sample * n_timesteps + t,\n",
    "                \"x\": data_axes[\"x\"][sample, t],\n",
    "                \"y\": data_axes[\"y\"][sample, t],\n",
    "                \"z\": data_axes[\"z\"][sample, t],\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(os.path.join(output_path, f\"{sensor_name}_timeseries.csv\"), index=False)\n",
    "\n",
    "    print(f\"Saved: {sensor_name}_timeseries.csv → shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d29e4cc2-2ba2-4225-9f80-e83e22cb02dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formatted_timeseries/train/body_gyro_timeseries.csv\n",
      "formatted_timeseries/train/body_acc_timeseries.csv\n",
      "formatted_timeseries/train/total_acc_timeseries.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"formatted_timeseries/train\"\n",
    "\n",
    "for file in os.listdir(output_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(output_path, file)   \n",
    "        print(file_path)\n",
    "        df = pd.read_csv(file_path)\n",
    "        # df.drop(columns=['timestep'], inplace=True)\n",
    "        df.rename(columns={\"x\":\"x-axis\", \"y\":\"y-axis\", \"z\":\"z-axis\"}, inplace=True)\n",
    "        df.to_csv(file_path, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f13d70-365c-43e7-a81b-40e47be0e1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftse",
   "language": "python",
   "name": "ftse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
