{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc38cdc1-328c-4670-bdb3-eaf47fb49343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "OLD_ROOT = \"/data/TimeSeriesResearch/datasets/Satya\"\n",
    "NEW_ROOT = \"/data/TimeSeriesResearch/datasets/Satya_New\"\n",
    "\n",
    "def restructure_dataset(old_root=OLD_ROOT, new_root=NEW_ROOT):\n",
    "    os.makedirs(new_root, exist_ok=True)\n",
    "\n",
    "    for folder in tqdm(os.listdir(old_root), desc=\"Processing Folders\"):\n",
    "        folder_path = os.path.join(old_root, folder)\n",
    "        \n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if not file_name.lower().endswith(\".csv\"):\n",
    "                continue\n",
    "            \n",
    "            parts = file_name.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                label = '_'.join(parts[2:]).replace('.csv', '')\n",
    "                index = parts[1]\n",
    "            else:\n",
    "                label = \"Unknown\"\n",
    "                index = parts[1] if len(parts) > 1 else \"0\"\n",
    "\n",
    "            label_folder = os.path.join(new_root, folder, label)\n",
    "            os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "            new_file_name = f\"file_{index}.csv\"\n",
    "            src_path = os.path.join(folder_path, file_name)\n",
    "            dst_path = os.path.join(label_folder, new_file_name)\n",
    "\n",
    "            try:\n",
    "                shutil.copy(src_path, dst_path)\n",
    "                print(f\"Moved: {src_path} -> {dst_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error moving {src_path} to {dst_path}: {e}\")\n",
    "\n",
    "    print(\"Restructuring complete.\")\n",
    "\n",
    "restructure_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c7ce4-bfc5-4633-9e1a-a45a7b639f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### File movement\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "source_dir = \"/data/TimeSeriesResearch/datasets/kaggle/processed/processed_datasets_labelled_separated/SKAB - Skoltech Anomaly Benchmark\"\n",
    "dest_dir = \"/data/TimeSeriesResearch/datasets/Satya_New/SKAB - Skoltech Anomaly Benchmark\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(dest_dir, exist_ok=True)\n",
    "\n",
    "# Dictionary to keep track of the file counts for each label\n",
    "label_count = {}\n",
    "\n",
    "# Process each file in the source directory\n",
    "for file_name in tqdm(os.listdir(source_dir), desc=\"Processing files\"):\n",
    "    # Check if it's a CSV file\n",
    "    if not file_name.endswith(\".csv\"):\n",
    "        continue\n",
    "\n",
    "    # Split the file name to extract the label\n",
    "    parts = file_name.split('_')\n",
    "    label = parts[-1].replace('.csv', '').strip()\n",
    "    \n",
    "    # Create the label directory if it doesn't exist\n",
    "    label_dir = os.path.join(dest_dir, label)\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "    # Keep count of files within each label\n",
    "    if label not in label_count:\n",
    "        label_count[label] = 0\n",
    "\n",
    "    # Construct the new file name based on the order\n",
    "    new_file_name = f\"file_{label_count[label]}.csv\"\n",
    "    label_count[label] += 1\n",
    "\n",
    "    # Full paths for reading, processing, and moving\n",
    "    src_path = os.path.join(source_dir, file_name)\n",
    "    dest_path = os.path.join(label_dir, new_file_name)\n",
    "\n",
    "    # Load the CSV and drop the label column\n",
    "    try:\n",
    "        df = pd.read_csv(src_path)\n",
    "        if \"Label\" in df.columns:\n",
    "            df = df.drop(columns=[\"Label\"], errors='ignore')\n",
    "\n",
    "        # Save the modified file in the new location\n",
    "        df.to_csv(dest_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "print(\"Files processed and moved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44514e95-d098-41af-8bd5-b3bbf2200d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:   0%|                                                                                                                                                                                                             | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_0\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_1\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_2\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_3\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_4\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_5\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_6\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_7\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_8\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_9\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_10\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_11\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_12\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_13\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_14\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve1/file_15\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve2/file_0\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve2/file_1\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve2/file_2\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/valve2/file_3\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_0\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_1\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_2\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_3\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_4\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_5\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_6\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_7\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_8\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_9\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_10\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_11\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_12\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/other/file_13\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_0\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_1\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_2\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_3\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_4\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_5\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_6\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_7\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_8\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_9\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_10\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_11\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_12\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_13\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_14\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_15\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_16\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_17\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_18\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_19\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_20\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_21\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_22\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_23\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_24\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_25\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_26\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_27\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_28\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_29\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_30\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_31\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_32\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_33\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_34\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_35\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_36\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:   6%|██████████▉                                                                                                                                                                                          | 1/18 [00:00<00:04,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_38\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_39\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_40\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_41\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_42\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_43\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_44\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_45\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_46\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_47\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_48\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_49\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_50\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_51\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_52\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_53\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_54\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_55\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_56\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_57\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_58\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_59\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_60\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_61\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_62\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_63\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_64\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_65\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_66\n",
      "Created dataset at: Satya_New/SKAB - Skoltech Anomaly Benchmark/Normal Operation/file_67\n",
      "Created dataset at: Satya_New/Accelerometer/BuildingStairMove/file_0\n",
      "Created dataset at: Satya_New/Accelerometer/BuildingStairMove/file_1\n",
      "Created dataset at: Satya_New/Accelerometer/OutdoorMove/file_0\n",
      "Created dataset at: Satya_New/Accelerometer/OutdoorMove/file_1\n",
      "Created dataset at: Satya_New/Accelerometer/EscalatorMove/file_0\n",
      "Created dataset at: Satya_New/Accelerometer/EscalatorMove/file_1\n",
      "Created dataset at: Satya_New/Accelerometer/BuildingElevatorMove/file_0\n",
      "Created dataset at: Satya_New/Accelerometer/BuildingElevatorMove/file_1\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_0\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_1\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_2\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_3\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_4\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_5\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_6\n",
      "Created dataset at: Satya_New/Accelerometer/FloorMove/file_7\n",
      "Created dataset at: Satya_New/Accelerometer/IndoorMove/file_0\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_0\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_1\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_2\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_3\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_4\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:  17%|████████████████████████████████▊                                                                                                                                                                    | 3/18 [00:01<00:07,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/BCSV/Ball/file_6\n",
      "Created dataset at: Satya_New/BCSV/Ball/file_7\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_0\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_1\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_2\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_3\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_4\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_5\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_6\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_7\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_8\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_9\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_10\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_11\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_12\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_13\n",
      "Created dataset at: Satya_New/Wyoming/SO2/file_14\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_0\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_1\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_2\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_3\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_4\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_5\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_6\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_7\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_8\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_9\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_10\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_11\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_12\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_13\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_14\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_15\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_16\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_17\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_18\n",
      "Created dataset at: Satya_New/Maryland/Ozone/file_19\n",
      "Created dataset at: Satya_New/California/CO/file_0\n",
      "Created dataset at: Satya_New/California/CO/file_1\n",
      "Created dataset at: Satya_New/California/CO/file_2\n",
      "Created dataset at: Satya_New/California/CO/file_3\n",
      "Created dataset at: Satya_New/California/CO/file_4\n",
      "Created dataset at: Satya_New/California/CO/file_5\n",
      "Created dataset at: Satya_New/California/CO/file_6\n",
      "Created dataset at: Satya_New/California/CO/file_7\n",
      "Created dataset at: Satya_New/California/CO/file_8\n",
      "Created dataset at: Satya_New/California/CO/file_9\n",
      "Created dataset at: Satya_New/California/CO/file_10\n",
      "Created dataset at: Satya_New/California/CO/file_11\n",
      "Created dataset at: Satya_New/California/CO/file_12\n",
      "Created dataset at: Satya_New/California/CO/file_13\n",
      "Created dataset at: Satya_New/California/CO/file_14\n",
      "Created dataset at: Satya_New/California/CO/file_15\n",
      "Created dataset at: Satya_New/California/CO/file_16\n",
      "Created dataset at: Satya_New/California/CO/file_17\n",
      "Created dataset at: Satya_New/California/CO/file_18\n",
      "Created dataset at: Satya_New/California/CO/file_19\n",
      "Created dataset at: Satya_New/California/CO/file_20\n",
      "Created dataset at: Satya_New/California/CO/file_21\n",
      "Created dataset at: Satya_New/California/CO/file_22\n",
      "Created dataset at: Satya_New/California/CO/file_23\n",
      "Created dataset at: Satya_New/California/CO/file_24\n",
      "Created dataset at: Satya_New/California/CO/file_25\n",
      "Created dataset at: Satya_New/California/CO/file_26\n",
      "Created dataset at: Satya_New/California/CO/file_27\n",
      "Created dataset at: Satya_New/California/CO/file_28\n",
      "Created dataset at: Satya_New/California/CO/file_29\n",
      "Created dataset at: Satya_New/California/CO/file_30\n",
      "Created dataset at: Satya_New/California/CO/file_31\n",
      "Created dataset at: Satya_New/California/CO/file_32\n",
      "Created dataset at: Satya_New/California/CO/file_33\n",
      "Created dataset at: Satya_New/California/CO/file_34\n",
      "Created dataset at: Satya_New/California/CO/file_35\n",
      "Created dataset at: Satya_New/California/CO/file_36\n",
      "Created dataset at: Satya_New/California/CO/file_37\n",
      "Created dataset at: Satya_New/California/CO/file_38\n",
      "Created dataset at: Satya_New/California/CO/file_39\n",
      "Created dataset at: Satya_New/California/CO/file_40\n",
      "Created dataset at: Satya_New/California/CO/file_41\n",
      "Created dataset at: Satya_New/California/CO/file_42\n",
      "Created dataset at: Satya_New/California/CO/file_43\n",
      "Created dataset at: Satya_New/California/CO/file_44\n",
      "Created dataset at: Satya_New/California/CO/file_45\n",
      "Created dataset at: Satya_New/California/CO/file_46\n",
      "Created dataset at: Satya_New/California/CO/file_47\n",
      "Created dataset at: Satya_New/California/CO/file_48\n",
      "Created dataset at: Satya_New/California/CO/file_49\n",
      "Created dataset at: Satya_New/California/CO/file_50\n",
      "Created dataset at: Satya_New/California/CO/file_51\n",
      "Created dataset at: Satya_New/California/CO/file_52\n",
      "Created dataset at: Satya_New/California/CO/file_53\n",
      "Created dataset at: Satya_New/California/CO/file_54\n",
      "Created dataset at: Satya_New/California/CO/file_55\n",
      "Created dataset at: Satya_New/California/CO/file_56\n",
      "Created dataset at: Satya_New/California/CO/file_57\n",
      "Created dataset at: Satya_New/California/CO/file_58\n",
      "Created dataset at: Satya_New/California/CO/file_59\n",
      "Created dataset at: Satya_New/California/CO/file_60\n",
      "Created dataset at: Satya_New/California/CO/file_61\n",
      "Created dataset at: Satya_New/California/CO/file_62\n",
      "Created dataset at: Satya_New/California/CO/file_63\n",
      "Created dataset at: Satya_New/California/CO/file_64\n",
      "Created dataset at: Satya_New/California/CO/file_65\n",
      "Created dataset at: Satya_New/California/CO/file_66\n",
      "Created dataset at: Satya_New/California/CO/file_67\n",
      "Created dataset at: Satya_New/California/CO/file_68\n",
      "Created dataset at: Satya_New/California/CO/file_69\n",
      "Created dataset at: Satya_New/California/CO/file_70\n",
      "Created dataset at: Satya_New/California/CO/file_71\n",
      "Created dataset at: Satya_New/California/CO/file_72\n",
      "Created dataset at: Satya_New/California/CO/file_73\n",
      "Created dataset at: Satya_New/California/CO/file_74\n",
      "Created dataset at: Satya_New/California/CO/file_75\n",
      "Created dataset at: Satya_New/California/CO/file_76\n",
      "Created dataset at: Satya_New/California/CO/file_77\n",
      "Created dataset at: Satya_New/California/CO/file_78\n",
      "Created dataset at: Satya_New/California/CO/file_79\n",
      "Created dataset at: Satya_New/California/CO/file_80\n",
      "Created dataset at: Satya_New/California/CO/file_81\n",
      "Created dataset at: Satya_New/California/CO/file_82\n",
      "Created dataset at: Satya_New/California/CO/file_83\n",
      "Created dataset at: Satya_New/California/CO/file_84\n",
      "Created dataset at: Satya_New/California/CO/file_85\n",
      "Created dataset at: Satya_New/California/CO/file_86\n",
      "Created dataset at: Satya_New/California/CO/file_87\n",
      "Created dataset at: Satya_New/California/CO/file_88\n",
      "Created dataset at: Satya_New/California/CO/file_89\n",
      "Created dataset at: Satya_New/California/CO/file_90\n",
      "Created dataset at: Satya_New/California/CO/file_91\n",
      "Created dataset at: Satya_New/California/CO/file_92\n",
      "Created dataset at: Satya_New/California/CO/file_93\n",
      "Created dataset at: Satya_New/California/CO/file_94\n",
      "Created dataset at: Satya_New/California/CO/file_95\n",
      "Created dataset at: Satya_New/California/CO/file_96\n",
      "Created dataset at: Satya_New/California/CO/file_97\n",
      "Created dataset at: Satya_New/California/CO/file_98\n",
      "Created dataset at: Satya_New/California/CO/file_99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:  50%|██████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                  | 9/18 [00:01<00:01,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/California/CO/file_100\n",
      "Created dataset at: Satya_New/California/CO/file_101\n",
      "Created dataset at: Satya_New/California/CO/file_102\n",
      "Created dataset at: Satya_New/California/CO/file_103\n",
      "Created dataset at: Satya_New/California/CO/file_104\n",
      "Created dataset at: Satya_New/California/CO/file_105\n",
      "Created dataset at: Satya_New/California/CO/file_106\n",
      "Created dataset at: Satya_New/California/CO/file_107\n",
      "Created dataset at: Satya_New/California/CO/file_108\n",
      "Created dataset at: Satya_New/California/CO/file_109\n",
      "Created dataset at: Satya_New/Delaware/SO2/file_0\n",
      "Created dataset at: Satya_New/Delaware/SO2/file_1\n",
      "Created dataset at: Satya_New/Delaware/SO2/file_2\n",
      "Created dataset at: Satya_New/Delaware/SO2/file_3\n",
      "Created dataset at: Satya_New/Delaware/SO2/file_4\n",
      "Created dataset at: Satya_New/Airquality_pattern/Unknown/file_0\n",
      "Created dataset at: Satya_New/Airquality_pattern/Unknown/file_1\n",
      "Created dataset at: Satya_New/Florida/PM25/file_0\n",
      "Created dataset at: Satya_New/Florida/PM25/file_1\n",
      "Created dataset at: Satya_New/Florida/PM25/file_2\n",
      "Created dataset at: Satya_New/Florida/PM25/file_3\n",
      "Created dataset at: Satya_New/Florida/PM25/file_4\n",
      "Created dataset at: Satya_New/Florida/PM25/file_5\n",
      "Created dataset at: Satya_New/Florida/PM25/file_6\n",
      "Created dataset at: Satya_New/Florida/PM25/file_7\n",
      "Created dataset at: Satya_New/Florida/PM25/file_8\n",
      "Created dataset at: Satya_New/Florida/PM25/file_9\n",
      "Created dataset at: Satya_New/Florida/PM25/file_10\n",
      "Created dataset at: Satya_New/Florida/PM25/file_11\n",
      "Created dataset at: Satya_New/Florida/PM25/file_12\n",
      "Created dataset at: Satya_New/Florida/PM25/file_13\n",
      "Created dataset at: Satya_New/Florida/PM25/file_14\n",
      "Created dataset at: Satya_New/Florida/PM25/file_15\n",
      "Created dataset at: Satya_New/Florida/PM25/file_16\n",
      "Created dataset at: Satya_New/Florida/PM25/file_17\n",
      "Created dataset at: Satya_New/Florida/PM25/file_18\n",
      "Created dataset at: Satya_New/Florida/PM25/file_19\n",
      "Created dataset at: Satya_New/Florida/PM25/file_20\n",
      "Created dataset at: Satya_New/Florida/PM25/file_21\n",
      "Created dataset at: Satya_New/Florida/PM25/file_22\n",
      "Created dataset at: Satya_New/Florida/PM25/file_23\n",
      "Created dataset at: Satya_New/Florida/PM25/file_24\n",
      "Created dataset at: Satya_New/Florida/PM25/file_25\n",
      "Created dataset at: Satya_New/Florida/PM25/file_26\n",
      "Created dataset at: Satya_New/Florida/PM25/file_27\n",
      "Created dataset at: Satya_New/Florida/PM25/file_28\n",
      "Created dataset at: Satya_New/Florida/PM25/file_29\n",
      "Created dataset at: Satya_New/Florida/PM25/file_30\n",
      "Created dataset at: Satya_New/Florida/PM25/file_31\n",
      "Created dataset at: Satya_New/Florida/PM25/file_32\n",
      "Created dataset at: Satya_New/Florida/PM25/file_33\n",
      "Created dataset at: Satya_New/Florida/PM25/file_34\n",
      "Created dataset at: Satya_New/Florida/PM25/file_35\n",
      "Created dataset at: Satya_New/Florida/PM25/file_36\n",
      "Created dataset at: Satya_New/Florida/PM25/file_37\n",
      "Created dataset at: Satya_New/Florida/PM25/file_38\n",
      "Created dataset at: Satya_New/Florida/PM25/file_39\n",
      "Created dataset at: Satya_New/Florida/PM25/file_40\n",
      "Created dataset at: Satya_New/Florida/PM25/file_41\n",
      "Created dataset at: Satya_New/Florida/PM25/file_42\n",
      "Created dataset at: Satya_New/Florida/PM25/file_43\n",
      "Created dataset at: Satya_New/Florida/PM25/file_44\n",
      "Created dataset at: Satya_New/Florida/PM25/file_45\n",
      "Created dataset at: Satya_New/Florida/PM25/file_46\n",
      "Created dataset at: Satya_New/Florida/PM25/file_47\n",
      "Created dataset at: Satya_New/Florida/PM25/file_48\n",
      "Created dataset at: Satya_New/Florida/PM25/file_49\n",
      "Created dataset at: Satya_New/Florida/PM25/file_50\n",
      "Created dataset at: Satya_New/Florida/PM25/file_51\n",
      "Created dataset at: Satya_New/Florida/PM25/file_52\n",
      "Created dataset at: Satya_New/Texas/Pb/file_0\n",
      "Created dataset at: Satya_New/Texas/Pb/file_1\n",
      "Created dataset at: Satya_New/Texas/Pb/file_2\n",
      "Created dataset at: Satya_New/Texas/Pb/file_3\n",
      "Created dataset at: Satya_New/Texas/Pb/file_4\n",
      "Created dataset at: Satya_New/Michigan/CO/file_0\n",
      "Created dataset at: Satya_New/Michigan/CO/file_1\n",
      "Created dataset at: Satya_New/Michigan/CO/file_2\n",
      "Created dataset at: Satya_New/Michigan/CO/file_3\n",
      "Created dataset at: Satya_New/Michigan/CO/file_4\n",
      "Created dataset at: Satya_New/Michigan/CO/file_5\n",
      "Created dataset at: Satya_New/Michigan/CO/file_6\n",
      "Created dataset at: Satya_New/Michigan/CO/file_7\n",
      "Created dataset at: Satya_New/Michigan/CO/file_8\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_0\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_1\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_2\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_3\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_4\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_5\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_6\n",
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 12/18 [00:03<00:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/OCSV/Outer_and_Ball/file_8\n",
      "Created dataset at: Satya_New/turbofan/Unknown/file_0\n",
      "Created dataset at: Satya_New/turbofan/Unknown/file_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:  72%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                      | 13/18 [00:03<00:01,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/turbofan/Unknown/file_2\n",
      "Created dataset at: Satya_New/turbofan/Unknown/file_3\n",
      "Created dataset at: Satya_New/NewYork/PM1/file_0\n",
      "Created dataset at: Satya_New/NewYork/PM1/file_1\n",
      "Created dataset at: Satya_New/NewYork/PM1/file_2\n",
      "Created dataset at: Satya_New/NewYork/PM1/file_3\n",
      "Created dataset at: Satya_New/NewYork/PM1/file_4\n",
      "Created dataset at: Satya_New/IOCSV/Inner_and_Outer/file_0\n",
      "Created dataset at: Satya_New/IOCSV/Inner_and_Outer/file_1\n",
      "Created dataset at: Satya_New/IOCSV/Inner_and_Outer/file_2\n",
      "Created dataset at: Satya_New/IOCSV/Inner_and_Outer/file_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New:  83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                | 15/18 [00:04<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/IOCSV/Inner_and_Outer/file_4\n",
      "Created dataset at: Satya_New/Illinois/NO/file_0\n",
      "Created dataset at: Satya_New/Illinois/NO/file_1\n",
      "Created dataset at: Satya_New/Illinois/NO/file_2\n",
      "Created dataset at: Satya_New/Illinois/NO/file_3\n",
      "Created dataset at: Satya_New/Illinois/NO/file_4\n",
      "Created dataset at: Satya_New/Illinois/NO/file_5\n",
      "Created dataset at: Satya_New/Illinois/NO/file_6\n",
      "Created dataset at: Satya_New/Illinois/NO/file_7\n",
      "Created dataset at: Satya_New/Gyrometer/BuildingStairMove/file_0\n",
      "Created dataset at: Satya_New/Gyrometer/BuildingStairMove/file_1\n",
      "Created dataset at: Satya_New/Gyrometer/OutdoorMove/file_0\n",
      "Created dataset at: Satya_New/Gyrometer/OutdoorMove/file_1\n",
      "Created dataset at: Satya_New/Gyrometer/EscalatorMove/file_0\n",
      "Created dataset at: Satya_New/Gyrometer/EscalatorMove/file_1\n",
      "Created dataset at: Satya_New/Gyrometer/BuildingElevatorMove/file_0\n",
      "Created dataset at: Satya_New/Gyrometer/BuildingElevatorMove/file_1\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_0\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_1\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_2\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_3\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_4\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_5\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_6\n",
      "Created dataset at: Satya_New/Gyrometer/FloorMove/file_7\n",
      "Created dataset at: Satya_New/Gyrometer/IndoorMove/file_0\n",
      "Created dataset at: Satya_New/IBCSV/Inner_and_Ball/file_0\n",
      "Created dataset at: Satya_New/IBCSV/Inner_and_Ball/file_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing /data/TimeSeriesResearch/datasets/Satya_New: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:05<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset at: Satya_New/IBCSV/Inner_and_Ball/file_2\n",
      "Created dataset at: Satya_New/IBCSV/Inner_and_Ball/file_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from ftse.data.Dataset import UnwindowedDataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "\n",
    "ROOT_DIRS = [\n",
    "    '/data/TimeSeriesResearch/datasets/Satya_New'\n",
    "]\n",
    "\n",
    "H5_FILE = '/data/TimeSeriesResearch/datasets/satya_data2.h5'\n",
    "\n",
    "def create_h5py_dataset_from_root_dirs(root_dirs=ROOT_DIRS, h5_file=H5_FILE):\n",
    "    with h5py.File(h5_file, \"w\") as h5f:\n",
    "        for root_dir in root_dirs:\n",
    "            root_prefix = os.path.basename(os.path.normpath(root_dir))\n",
    "\n",
    "            for dataset_folder in tqdm(os.listdir(root_dir), desc=f\"Datasets in {root_dir}\"):\n",
    "                dataset_path = os.path.join(root_dir, dataset_folder)\n",
    "                if not os.path.isdir(dataset_path):\n",
    "                    print(\"skipping\", dataset_path)\n",
    "                    print(\"\\n\"*50)\n",
    "                    continue\n",
    "                    \n",
    "                #For labels\n",
    "                for subfolder in os.listdir(dataset_path):\n",
    "                    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "                    if not os.path.isdir(subfolder_path):\n",
    "                        continue\n",
    "\n",
    "                    for csv_file in os.listdir(subfolder_path):\n",
    "                        if not csv_file.lower().endswith(\".csv\"):\n",
    "                            continue\n",
    "                            \n",
    "                        group_path = f\"{root_prefix}/{dataset_folder}/{subfolder}\"\n",
    "                        group = h5f.require_group(group_path)\n",
    "                        #print(\"group\",group)\n",
    "\n",
    "                        csv_path = os.path.join(subfolder_path, csv_file)\n",
    "                        df = pd.read_csv(csv_path)\n",
    "\n",
    "                        drop_columns = ['Unnamed: 0', 'time_sec', 'Time', 'Label']\n",
    "                        df = df.drop(columns=[col for col in drop_columns if col in df.columns], errors='ignore')\n",
    "\n",
    "                        column_names = df.columns.tolist()\n",
    "                        data_array = df.to_numpy()\n",
    "                        dataset_name = f\"file_{len(group)}\"\n",
    "                        #print(group_path, \"--\", dataset_name)\n",
    "                        dset = group.create_dataset(dataset_name, data=data_array)\n",
    "                        dset.attrs[\"descriptions\"] = list(column_names)\n",
    "                        #print(f\"Created dataset at: {group_path}/{dataset_name}\")\n",
    "    print(\"Flat HDF5 file created successfully:\", h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "904be9ce-5c2d-4dc8-a61a-866678b6d425",
   "metadata": {},
   "outputs": [],
   "source": [
    "H5_FILE = '/data/TimeSeriesResearch/datasets/satya_data_New0522.h5'\n",
    "\n",
    "def load_h5py_dataset(h5_file=H5_FILE, window_size=None, stride=None, concat=False):\n",
    "    datasets = defaultdict(list)\n",
    "    def recursive_group_traversal(group, path=\"\"):\n",
    "        for key in group.keys():\n",
    "            item = group[key]\n",
    "\n",
    "            if isinstance(item, h5py.Group):\n",
    "                recursive_group_traversal(item, path + \"/\" + key)\n",
    "            elif isinstance(item, h5py.Dataset):\n",
    "                label = path.split(\"/\")[-1]\n",
    "                dataset_name = path.strip(\"/\").split(\"/\")[-2]\n",
    "                \n",
    "                datasets[dataset_name].append(\n",
    "                    UnwindowedDataset(\n",
    "                        data=item,\n",
    "                        dataset_name=dataset_name,\n",
    "                        descriptions=item.attrs.get(\"descriptions\", []),\n",
    "                        label=label\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    f = h5py.File(h5_file, 'r')\n",
    "    recursive_group_traversal(f)\n",
    "\n",
    "    if window_size and stride:\n",
    "        for dataset_name in datasets:\n",
    "            datasets[dataset_name] = [\n",
    "                dataset.window(window_size=window_size, stride=stride)\n",
    "                for dataset in datasets[dataset_name]\n",
    "            ]\n",
    "\n",
    "    if concat:\n",
    "        for dataset_name in datasets:\n",
    "            datasets[dataset_name] = torch.utils.data.ConcatDataset(\n",
    "                datasets[dataset_name]\n",
    "            )\n",
    "\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "555dfd79-2848-40a6-8a0e-9a2460e235d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# H5_FILE = '/data/TimeSeriesResearch/datasets/satya_new_data2.h5'\n",
    "from collections import defaultdict\n",
    "from ftse.data.Dataset import UnwindowedDataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "datasets = load_h5py_dataset(H5_FILE, window_size=12, stride=1, concat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fc62d-4f3f-4ac4-be71-aeff422a4d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "abf1c991-880a-4e2d-b687-4be4fab46910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Accelerometer', 'Airquality_pattern', 'Appliances energy prediction Data Set', 'BCSV', 'California', 'Delaware', 'Florida', 'Gas sensor array temperature modulation', 'Gyrometer', 'Household Electric Power Consumption', 'IBCSV', 'IOCSV', 'Illinois', 'Machinery Fault Diagnosis', 'Maryland', 'MetroPT-3 Dataset', 'Michigan', 'NewYork', 'Nightly', 'OCSV', 'Predictive Maintenance Of Hydraulics System', 'SKAB - Skoltech Anomaly Benchmark', 'Texas', 'Unleashing the Power of Wearables', 'Wyoming', 'c3server', 'liu', 'turbofan'])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "82e94bb7-ec24-4395-93da-b3c5c08aa71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(data=tensor([[1.8778e+01, 1.4780e+00, 2.3162e+03, 1.0137e+01, 8.9575e+00, 1.4543e+02,\n",
       "         1.1852e+02, 2.7281e+00, 0.0000e+00, 8.4242e+00, 8.3840e+00, 2.9586e+01,\n",
       "         5.6367e+01, 6.1004e+01, 5.8289e+01, 5.2168e+01, 7.7500e-01],\n",
       "        [1.8790e+01, 1.4790e+00, 2.1761e+03, 7.8790e+00, 8.9548e+00, 1.4146e+02,\n",
       "         1.1596e+02, 2.0582e+00, 0.0000e+00, 8.4230e+00, 8.3815e+00, 6.9977e+01,\n",
       "         5.6270e+01, 6.1016e+01, 5.8312e+01, 5.2156e+01, 7.0600e-01],\n",
       "        [1.8838e+01, 1.4850e+00, 2.1733e+03, 7.8253e+00, 8.9383e+00, 1.4132e+02,\n",
       "         1.1589e+02, 2.0231e+00, 0.0000e+00, 8.4181e+00, 8.3774e+00, 6.9977e+01,\n",
       "         5.6277e+01, 6.0988e+01, 5.8312e+01, 5.2168e+01, 6.6100e-01],\n",
       "        [1.8761e+01, 1.4790e+00, 2.1723e+03, 7.7977e+00, 8.9390e+00, 1.4133e+02,\n",
       "         1.1586e+02, 2.0128e+00, 0.0000e+00, 8.4173e+00, 8.3724e+00, 6.9317e+01,\n",
       "         5.6277e+01, 6.1004e+01, 5.8301e+01, 5.2156e+01, 6.3200e-01],\n",
       "        [1.8749e+01, 1.4780e+00, 2.1716e+03, 7.7988e+00, 8.9398e+00, 1.4130e+02,\n",
       "         1.1584e+02, 2.0149e+00, 0.0000e+00, 8.4160e+00, 8.3754e+00, 6.9317e+01,\n",
       "         5.6383e+01, 6.1023e+01, 5.8305e+01, 5.2156e+01, 6.1100e-01],\n",
       "        [1.8769e+01, 1.4810e+00, 2.1713e+03, 7.7893e+00, 8.9473e+00, 1.4130e+02,\n",
       "         1.1584e+02, 2.0593e+00, 0.0000e+00, 8.4194e+00, 8.3746e+00, 6.9261e+01,\n",
       "         5.6449e+01, 6.1020e+01, 5.8297e+01, 5.2156e+01, 6.0900e-01],\n",
       "        [1.8802e+01, 1.4780e+00, 2.1709e+03, 7.7727e+00, 8.9365e+00, 1.4127e+02,\n",
       "         1.1586e+02, 1.9963e+00, 0.0000e+00, 8.4201e+00, 8.3775e+00, 6.9261e+01,\n",
       "         5.6437e+01, 6.1078e+01, 5.8301e+01, 5.2160e+01, 6.1700e-01],\n",
       "        [1.8907e+01, 1.4900e+00, 2.1699e+03, 7.7668e+00, 8.9376e+00, 1.4129e+02,\n",
       "         1.1585e+02, 2.0296e+00, 0.0000e+00, 8.4207e+00, 8.3788e+00, 6.9113e+01,\n",
       "         5.6531e+01, 6.1098e+01, 5.8297e+01, 5.2168e+01, 5.9900e-01],\n",
       "        [1.8871e+01, 1.5050e+00, 2.1711e+03, 7.7642e+00, 8.9490e+00, 1.4124e+02,\n",
       "         1.1581e+02, 2.0285e+00, 0.0000e+00, 8.4277e+00, 8.3835e+00, 6.9113e+01,\n",
       "         5.6555e+01, 6.1090e+01, 5.8383e+01, 5.2156e+01, 6.0600e-01],\n",
       "        [1.8936e+01, 1.5070e+00, 2.2450e+03, 6.2015e+00, 8.9554e+00, 1.4929e+02,\n",
       "         1.2442e+02, 1.6506e+00, 0.0000e+00, 8.4307e+00, 8.3860e+00, 5.7124e+01,\n",
       "         5.6598e+01, 6.1102e+01, 5.8379e+01, 5.2145e+01, 6.0300e-01],\n",
       "        [1.8938e+01, 1.5100e+00, 2.3003e+03, 7.6449e+00, 8.9734e+00, 1.5098e+02,\n",
       "         1.2563e+02, 1.9636e+00, 0.0000e+00, 8.4374e+00, 8.3901e+00, 5.7124e+01,\n",
       "         5.6598e+01, 6.1117e+01, 5.8391e+01, 5.2168e+01, 6.1900e-01],\n",
       "        [1.8964e+01, 1.5070e+00, 2.2995e+03, 7.7080e+00, 8.9806e+00, 1.5099e+02,\n",
       "         1.2562e+02, 1.9395e+00, 0.0000e+00, 8.4380e+00, 8.3899e+00, 7.0180e+01,\n",
       "         5.6680e+01, 6.1145e+01, 5.8383e+01, 5.2156e+01, 6.1700e-01]],\n",
       "       dtype=torch.float64), descriptions=['Virtual cooling efficiency sensor in a hydraulic system with cooling-filtration circuits', 'Virtual cooling power sensor in a hydraulic system with cooling-filtration circuits', 'Motor power sensor in a hydraulic system with cooling-filtration circuits', 'Volume flow sensor 1 in a hydraulic system with cooling-filtration circuits', 'Volume flow sensor 2 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 1 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 2 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 3 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 4 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 5 in a hydraulic system with cooling-filtration circuits', 'Pressure sensor 6 in a hydraulic system with cooling-filtration circuits', 'Efficiency factor in a hydraulic system with cooling-filtration circuits', 'Temperature sensor 1 in a hydraulic system with cooling-filtration circuits', 'Temperature sensor 2 in a hydraulic system with cooling-filtration circuits', 'Temperature sensor 3 in a hydraulic system with cooling-filtration circuits', 'Temperature sensor 4 in a hydraulic system with cooling-filtration circuits', 'Vibration sensor in a hydraulic system with cooling-filtration circuits'], label='close to total failure-close to total failure-no leakage-close to total failure', dataset_name='Predictive Maintenance Of Hydraulics System', positions=None)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['Predictive Maintenance Of Hydraulics System'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "57e7b7f4-5fc4-4edf-b19b-778d70a1d427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in dataset: 6960\n",
      "Unique labels found: {'close to total failure-severe lag-severe leakage-severely reduced pressure', 'close to total failure-optimal switching behavior-weak leakage-slightly reduced pressure', 'full efficiency-close to total failure-severe leakage-severely reduced pressure', 'close to total failure-severe lag-weak leakage-slightly reduced pressure', 'full efficiency-severe lag-weak leakage-slightly reduced pressure', 'close to total failure-close to total failure-no leakage-close to total failure', 'full efficiency-severe lag-no leakage-severely reduced pressure', 'close to total failure-optimal switching behavior-weak leakage-close to total failure', 'reduced efficiency-optimal switching behavior-severe leakage-severely reduced pressure', 'reduced efficiency-small lag-severe leakage-slightly reduced pressure', 'close to total failure-optimal switching behavior-severe leakage-close to total failure', 'close to total failure-close to total failure-severe leakage-optimal pressure', 'full efficiency-optimal switching behavior-no leakage-severely reduced pressure', 'reduced efficiency-severe lag-weak leakage-slightly reduced pressure', 'close to total failure-small lag-weak leakage-close to total failure', 'full efficiency-small lag-severe leakage-close to total failure', 'full efficiency-small lag-severe leakage-slightly reduced pressure', 'full efficiency-optimal switching behavior-severe leakage-slightly reduced pressure', 'reduced efficiency-severe lag-no leakage-slightly reduced pressure', 'full efficiency-severe lag-weak leakage-severely reduced pressure', 'reduced efficiency-optimal switching behavior-weak leakage-optimal pressure', 'reduced efficiency-small lag-weak leakage-close to total failure', 'reduced efficiency-optimal switching behavior-severe leakage-optimal pressure', 'reduced efficiency-severe lag-no leakage-severely reduced pressure', 'full efficiency-severe lag-severe leakage-close to total failure', 'reduced efficiency-severe lag-weak leakage-optimal pressure', 'reduced efficiency-close to total failure-no leakage-slightly reduced pressure', 'close to total failure-optimal switching behavior-severe leakage-severely reduced pressure', 'full efficiency-optimal switching behavior-weak leakage-severely reduced pressure', 'full efficiency-small lag-weak leakage-optimal pressure', 'close to total failure-severe lag-no leakage-close to total failure', 'reduced efficiency-optimal switching behavior-severe leakage-close to total failure', 'reduced efficiency-close to total failure-no leakage-severely reduced pressure', 'full efficiency-severe lag-severe leakage-slightly reduced pressure', 'close to total failure-small lag-severe leakage-close to total failure', 'reduced efficiency-severe lag-severe leakage-severely reduced pressure', 'reduced efficiency-small lag-weak leakage-severely reduced pressure', 'reduced efficiency-close to total failure-weak leakage-severely reduced pressure', 'reduced efficiency-severe lag-weak leakage-severely reduced pressure', 'reduced efficiency-severe lag-weak leakage-close to total failure', 'full efficiency-small lag-no leakage-close to total failure', 'close to total failure-severe lag-severe leakage-close to total failure', 'full efficiency-small lag-no leakage-severely reduced pressure', 'full efficiency-close to total failure-weak leakage-slightly reduced pressure', 'reduced efficiency-optimal switching behavior-weak leakage-close to total failure', 'full efficiency-severe lag-no leakage-slightly reduced pressure', 'full efficiency-severe lag-severe leakage-severely reduced pressure', 'reduced efficiency-optimal switching behavior-no leakage-close to total failure', 'full efficiency-severe lag-severe leakage-optimal pressure', 'close to total failure-small lag-severe leakage-severely reduced pressure', 'close to total failure-optimal switching behavior-no leakage-close to total failure', 'close to total failure-small lag-weak leakage-severely reduced pressure', 'full efficiency-optimal switching behavior-no leakage-close to total failure', 'full efficiency-close to total failure-no leakage-severely reduced pressure', 'full efficiency-small lag-no leakage-slightly reduced pressure', 'close to total failure-close to total failure-no leakage-slightly reduced pressure', 'reduced efficiency-optimal switching behavior-weak leakage-severely reduced pressure', 'reduced efficiency-small lag-severe leakage-optimal pressure', 'reduced efficiency-close to total failure-severe leakage-close to total failure', 'reduced efficiency-severe lag-severe leakage-optimal pressure', 'full efficiency-close to total failure-severe leakage-optimal pressure', 'full efficiency-severe lag-weak leakage-close to total failure', 'reduced efficiency-small lag-no leakage-close to total failure', 'close to total failure-close to total failure-severe leakage-close to total failure', 'full efficiency-close to total failure-weak leakage-severely reduced pressure', 'full efficiency-optimal switching behavior-severe leakage-optimal pressure', 'close to total failure-small lag-severe leakage-slightly reduced pressure', 'close to total failure-small lag-no leakage-severely reduced pressure', 'close to total failure-optimal switching behavior-severe leakage-optimal pressure', 'close to total failure-severe lag-weak leakage-optimal pressure', 'close to total failure-small lag-no leakage-slightly reduced pressure', 'close to total failure-optimal switching behavior-weak leakage-optimal pressure', 'reduced efficiency-close to total failure-weak leakage-optimal pressure', 'close to total failure-close to total failure-no leakage-optimal pressure', 'reduced efficiency-small lag-no leakage-slightly reduced pressure', 'full efficiency-close to total failure-no leakage-close to total failure', 'close to total failure-close to total failure-weak leakage-close to total failure', 'full efficiency-optimal switching behavior-weak leakage-optimal pressure', 'full efficiency-small lag-severe leakage-severely reduced pressure', 'full efficiency-small lag-no leakage-optimal pressure', 'full efficiency-small lag-weak leakage-slightly reduced pressure', 'reduced efficiency-severe lag-no leakage-optimal pressure', 'full efficiency-close to total failure-weak leakage-close to total failure', 'close to total failure-optimal switching behavior-no leakage-severely reduced pressure', 'close to total failure-severe lag-no leakage-optimal pressure', 'reduced efficiency-severe lag-no leakage-close to total failure', 'reduced efficiency-close to total failure-no leakage-optimal pressure', 'close to total failure-optimal switching behavior-no leakage-slightly reduced pressure', 'reduced efficiency-optimal switching behavior-severe leakage-slightly reduced pressure', 'reduced efficiency-optimal switching behavior-no leakage-optimal pressure', 'reduced efficiency-close to total failure-weak leakage-slightly reduced pressure', 'reduced efficiency-optimal switching behavior-weak leakage-slightly reduced pressure', 'close to total failure-close to total failure-severe leakage-severely reduced pressure', 'full efficiency-optimal switching behavior-severe leakage-close to total failure', 'full efficiency-small lag-weak leakage-severely reduced pressure', 'reduced efficiency-small lag-severe leakage-severely reduced pressure', 'full efficiency-optimal switching behavior-weak leakage-close to total failure', 'close to total failure-small lag-no leakage-close to total failure', 'reduced efficiency-optimal switching behavior-no leakage-slightly reduced pressure', 'close to total failure-close to total failure-weak leakage-severely reduced pressure', 'close to total failure-optimal switching behavior-severe leakage-slightly reduced pressure', 'reduced efficiency-small lag-severe leakage-close to total failure', 'close to total failure-optimal switching behavior-no leakage-optimal pressure', 'close to total failure-close to total failure-weak leakage-optimal pressure', 'reduced efficiency-close to total failure-severe leakage-optimal pressure', 'reduced efficiency-severe lag-severe leakage-close to total failure', 'full efficiency-close to total failure-severe leakage-close to total failure', 'close to total failure-close to total failure-no leakage-severely reduced pressure', 'full efficiency-close to total failure-severe leakage-slightly reduced pressure', 'close to total failure-small lag-weak leakage-optimal pressure', 'full efficiency-close to total failure-weak leakage-optimal pressure', 'close to total failure-severe lag-no leakage-severely reduced pressure', 'close to total failure-severe lag-severe leakage-optimal pressure', 'close to total failure-small lag-severe leakage-optimal pressure', 'reduced efficiency-severe lag-severe leakage-slightly reduced pressure', 'close to total failure-optimal switching behavior-weak leakage-severely reduced pressure', 'close to total failure-severe lag-weak leakage-severely reduced pressure', 'close to total failure-severe lag-severe leakage-slightly reduced pressure', 'full efficiency-close to total failure-no leakage-optimal pressure', 'full efficiency-optimal switching behavior-weak leakage-slightly reduced pressure', 'full efficiency-small lag-weak leakage-close to total failure', 'reduced efficiency-optimal switching behavior-no leakage-severely reduced pressure', 'full efficiency-severe lag-no leakage-close to total failure', 'close to total failure-severe lag-weak leakage-close to total failure', 'reduced efficiency-close to total failure-severe leakage-severely reduced pressure', 'close to total failure-close to total failure-weak leakage-slightly reduced pressure', 'close to total failure-small lag-no leakage-optimal pressure', 'full efficiency-close to total failure-no leakage-slightly reduced pressure', 'full efficiency-severe lag-no leakage-optimal pressure', 'reduced efficiency-close to total failure-weak leakage-close to total failure', 'full efficiency-optimal switching behavior-severe leakage-severely reduced pressure', 'reduced efficiency-small lag-weak leakage-optimal pressure', 'reduced efficiency-close to total failure-severe leakage-slightly reduced pressure', 'full efficiency-optimal switching behavior-no leakage-slightly reduced pressure', 'reduced efficiency-small lag-no leakage-severely reduced pressure', 'full efficiency-small lag-severe leakage-optimal pressure', 'close to total failure-severe lag-no leakage-slightly reduced pressure', 'full efficiency-optimal switching behavior-no leakage-optimal pressure', 'close to total failure-close to total failure-severe leakage-slightly reduced pressure', 'reduced efficiency-small lag-no leakage-optimal pressure', 'full efficiency-severe lag-weak leakage-optimal pressure', 'reduced efficiency-close to total failure-no leakage-close to total failure', 'close to total failure-small lag-weak leakage-slightly reduced pressure'}\n"
     ]
    }
   ],
   "source": [
    "def get_unique_labels(dataset, max_samples=None):\n",
    "    unique_labels = set()\n",
    "    sample_count = len(dataset) if max_samples is None else min(max_samples, len(dataset))\n",
    "    \n",
    "    for i in range(sample_count):\n",
    "        try:\n",
    "            sample = dataset[i]\n",
    "            # Extract label from the sample\n",
    "            label = sample.label if hasattr(sample, 'label') else None\n",
    "            unique_labels.add(label)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {i}: {e}\")\n",
    "    \n",
    "    return unique_labels\n",
    "\n",
    "# Use the function\n",
    "dataset = datasets['Predictive Maintenance Of Hydraulics System']\n",
    "print(f\"Total samples in dataset: {len(dataset)}\")\n",
    "\n",
    "# Check first 1000 samples (adjust as needed)\n",
    "unique_labels = get_unique_labels(dataset, max_samples=len(dataset)-100)\n",
    "print(f\"Unique labels found: {unique_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c2ea39-fc9c-45ec-82f0-b9d1810971c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cbb4b-7355-42fd-8775-e9e9647470bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "794a20a6-f41d-4478-a82b-25780f75886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from ftse.data.Dataset import UnwindowedDataset\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "\n",
    "ROOT_DIRS = [\n",
    "    '/data/TimeSeriesResearch/datasets/Satya_New'\n",
    "]\n",
    "\n",
    "H5_FILE = '/data/TimeSeriesResearch/datasets/satya_data_New0522.h5'\n",
    "\n",
    "def create_h5py_dataset_from_root_dirs(root_dirs=ROOT_DIRS, h5_file=H5_FILE):\n",
    "    with h5py.File(h5_file, \"w\") as h5f:\n",
    "        for root_dir in root_dirs:\n",
    "            root_prefix = os.path.basename(os.path.normpath(root_dir))\n",
    "\n",
    "            for dataset_folder in tqdm(os.listdir(root_dir), desc=f\"Datasets in {root_dir}\"):\n",
    "                dataset_path = os.path.join(root_dir, dataset_folder)\n",
    "                if not os.path.isdir(dataset_path):\n",
    "                    continue\n",
    "                    \n",
    "                #For labels\n",
    "                print(\"dataset_path\", dataset_path)\n",
    "                for subfolder in os.listdir(dataset_path):\n",
    "                    subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "                    if not os.path.isdir(subfolder_path):\n",
    "                        continue\n",
    "                    \n",
    "                    print(\"subfolder_path\", subfolder_path)\n",
    "                    for csv_file in os.listdir(subfolder_path):\n",
    "                        if not csv_file.lower().endswith(\".csv\"):\n",
    "                            print(csv_file)\n",
    "                            continue\n",
    "                            \n",
    "                        group_path = f\"{root_prefix}/{dataset_folder}/{subfolder}\"\n",
    "                        group = h5f.require_group(group_path)\n",
    "                        #print(\"group\",group)\n",
    "\n",
    "                        csv_path = os.path.join(subfolder_path, csv_file)\n",
    "                        df = pd.read_csv(csv_path)\n",
    "\n",
    "                        drop_columns = ['Unnamed: 0', 'time_sec', 'Time', 'Label']\n",
    "                        df = df.drop(columns=[col for col in drop_columns if col in df.columns], errors='ignore')\n",
    "\n",
    "                        column_names = df.columns.tolist()\n",
    "                        data_array = df.to_numpy()\n",
    "                        dataset_name = f\"file_{len(group)}\"\n",
    "                        print(group_path, \"--\", dataset_name)\n",
    "                        dset = group.create_dataset(dataset_name, data=data_array)\n",
    "                        dset.attrs[\"descriptions\"] = list(column_names)\n",
    "                        #print(f\"Created dataset at: {group_path}/{dataset_name}\")\n",
    "    print(\"Flat HDF5 file created successfully:\", h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fe4b4020-e023-48e1-ac33-feaaabf9f657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c65bc914434dcebe05abb817ede1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Datasets in /data/TimeSeriesResearch/datasets/Satya_New3:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_path /data/TimeSeriesResearch/datasets/Satya_New3/valve1\n",
      "file_7.csv\n",
      "file_8.csv\n",
      "file_13.csv\n",
      "file_1.csv\n",
      "file_11.csv\n",
      "file_10.csv\n",
      "file_0.csv\n",
      "file_2.csv\n",
      "file_14.csv\n",
      "file_5.csv\n",
      "file_12.csv\n",
      "file_4.csv\n",
      "file_9.csv\n",
      "file_15.csv\n",
      "file_3.csv\n",
      "file_6.csv\n",
      "dataset_path /data/TimeSeriesResearch/datasets/Satya_New3/valve2\n",
      "file_1.csv\n",
      "file_0.csv\n",
      "file_2.csv\n",
      "file_3.csv\n",
      "dataset_path /data/TimeSeriesResearch/datasets/Satya_New3/other\n",
      "file_7.csv\n",
      "file_8.csv\n",
      "file_13.csv\n",
      "file_1.csv\n",
      "file_11.csv\n",
      "file_10.csv\n",
      "file_0.csv\n",
      "file_2.csv\n",
      "file_5.csv\n",
      "file_12.csv\n",
      "file_4.csv\n",
      "file_9.csv\n",
      "file_3.csv\n",
      "file_6.csv\n",
      "dataset_path /data/TimeSeriesResearch/datasets/Satya_New3/Normal Operation\n",
      "file_18.csv\n",
      "file_17.csv\n",
      "file_25.csv\n",
      "file_40.csv\n",
      "file_20.csv\n",
      "file_67.csv\n",
      "file_51.csv\n",
      "file_7.csv\n",
      "file_55.csv\n",
      "file_58.csv\n",
      "file_46.csv\n",
      "file_8.csv\n",
      "file_13.csv\n",
      "file_33.csv\n",
      "file_31.csv\n",
      "file_64.csv\n",
      "file_60.csv\n",
      "file_34.csv\n",
      "file_1.csv\n",
      "file_48.csv\n",
      "file_11.csv\n",
      "file_35.csv\n",
      "file_22.csv\n",
      "file_57.csv\n",
      "file_10.csv\n",
      "file_39.csv\n",
      "file_26.csv\n",
      "file_38.csv\n",
      "file_45.csv\n",
      "file_42.csv\n",
      "file_63.csv\n",
      "file_19.csv\n",
      "file_23.csv\n",
      "file_37.csv\n",
      "file_0.csv\n",
      "file_49.csv\n",
      "file_50.csv\n",
      "file_21.csv\n",
      "file_61.csv\n",
      "file_44.csv\n",
      "file_59.csv\n",
      "file_36.csv\n",
      "file_2.csv\n",
      "file_65.csv\n",
      "file_41.csv\n",
      "file_14.csv\n",
      "file_62.csv\n",
      "file_30.csv\n",
      "file_5.csv\n",
      "file_54.csv\n",
      "file_28.csv\n",
      "file_12.csv\n",
      "file_16.csv\n",
      "file_4.csv\n",
      "file_9.csv\n",
      "file_52.csv\n",
      "file_32.csv\n",
      "file_53.csv\n",
      "file_43.csv\n",
      "file_47.csv\n",
      "file_29.csv\n",
      "file_27.csv\n",
      "file_15.csv\n",
      "file_66.csv\n",
      "file_3.csv\n",
      "file_24.csv\n",
      "file_56.csv\n",
      "file_6.csv\n",
      "Flat HDF5 file created successfully: /data/TimeSeriesResearch/datasets/satya_data_sklob.h5\n"
     ]
    }
   ],
   "source": [
    "create_h5py_dataset_from_root_dirs()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftse",
   "language": "python",
   "name": "ftse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
